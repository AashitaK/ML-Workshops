{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise notebook for the second session (60 min)\n",
    "\n",
    "The exercise notebook involves some new concepts not covered in the guided session. You are encouraged to work in groups of 2-4 if that helps to speed things up. Please ask for help from the instructor and/or TAs. The session is time-bound, so make sure you are not stuck at a problem for too long before asking for help.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "\n",
    "import warnings\n",
    "warnings.simplefilter('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Feature engineering on the Titanic dataset to create a new column for group size (30 min):\n",
    "Loading the [Titanic dataset](https://www.kaggle.com/c/titanic):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = 'titanic/'\n",
    "train = pd.read_csv(path + 'train.csv') \n",
    "test = pd.read_csv(path + 'test.csv') "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a DataFrame named `df` by concatenating the `train` and `test` datasets one below the other. Hint: Use `concat()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a new column named *Family* by adding the columns *SibSp* and *Parch* and then add 1 to it. Note: [Here](https://www.kaggle.com/c/titanic/data) is the description for features *SibSp* and *Parch*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we check the survival rates with respect to the family size."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.barplot(x='Family', y='Survived', data=df);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some passengers that appear to be traveling alone by account of their family size were part of a group traveling on the same ticket. To see this, get all the passengers traveling on the ticket \"1601\" (there are 8 of them)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One can check that there are many tickets shared among passengers that may or may not be family members."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Ticket'].value_counts()[:15]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a new column named *TicketCount* that counts the total number of passengers traveling in each passengers' ticket.\n",
    "\n",
    "Hint: \n",
    "- First group passengers based on their tickets using `groupby()` on the *Ticket* column.\n",
    "- For the grouped object, pick any column that has no missing values.\n",
    "- Use `transform()` for this unique identifier column with the function `\"count\"` to create a new column *TicketCount*.\n",
    "\n",
    "For example, we created *MedianAge* using the following code:   \n",
    "```df['MedianAge'] = df.groupby('Title')['Age'].transform(\"median\")```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot the survival rates based on the *TicketCount* using `sns.barplot()` (see above)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It does seem that the number of co-travelers have an impact on the survival rates."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a new column named *GroupSize* by picking the maximum value among the columns *Family* and *TicketCount*.   \n",
    "Note: We consider groups to be either family members or those traveling on the same ticket.   \n",
    "Hint: Use built-in `max()` function for pandas on the two relevant columns with the appropriate value for the `axis` parameter. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot the survival rates based on the *GroupSize* using `sns.barplot()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check the number of rows where *Groupsize* is not equal to *Family*. Similarly, check the number of rows where *TicketCount* is not equal to *Family*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df['GroupSize'] != df['Family']].shape[0], \n",
    "df[df['GroupSize'] != df['TicketCount']].shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The output must be `(200, 84)`. Check your above code, if you get a different output."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Creating a new column using grouping on two columns of [Predict Future Sales](https://www.kaggle.com/c/competitive-data-science-predict-future-sales) dataset (10 min):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = 'competitive-data-science-predict-future-sales/'\n",
    "df = pd.read_csv(path + 'sales_train.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[The description](https://www.kaggle.com/c/competitive-data-science-predict-future-sales/data) for each of the following columns is as follows. \n",
    "- date: date in format dd/mm/yyyy\n",
    "- date_block_num: a consecutive month number, used for convenience. January 2013 is 0, February 2013 is 1,..., October 2015 is 33\n",
    "- shop_id: unique identifier of a shop\n",
    "- item_id: unique identifier of a product\n",
    "- item_price: current price of an item\n",
    "- item_cnt_day: number of products sold\n",
    "       \n",
    "The aim of the competition is to predict the monthly sales. We are given the daily sales of items in each shop in the column *item_cnt_day*. We want to create a new column named *item_cnt_monthly* that gives the monthly sales of the items using the columns *item_cnt_day* and *date_block_num*. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Currently, the rows are sorted based on the *date* column. We want them sorted first w.r.t. *date_block_num* and then  w.r.t. *item_id* within each *date_block_num*. Hint: Use `sort_values()` on the two columns: `'date_block_num','item_id'`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We sorted the rows so that it will make it easier to check whether our code below is working correctly. For the *date_block_num* equal to 0, we can see that the item with *item_id* 19 is sold once, one with *item_id* 27 is sold 7 times and so on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can use `groupby()` on the two columns - *date_block_num* and *item_id* and sum the values in the *item_cnt_day* column in each grouping as follows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.groupby(['date_block_num', 'item_id'])['item_cnt_day'].sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a new column named *item_cnt_monthly* that gives the monthly sales of the items\n",
    "\n",
    "Hint: Use `transform()` with the function `\"sum\"` along with `groupby()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check that the code indeed worked as expected."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head(25)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Merging columns from different datasets (20 min):"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A simple illustration to merge two datasets using `merge()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = pd.DataFrame({'CourseCode': ['PHYS024', 'CSCI35', 'ENGR156'], \n",
    "                   'CourseName': ['Mechanics and Wave Motion', \n",
    "                                  'Computer Science for Insight',\n",
    "                                 'Intro to Comm & Info Theory']})\n",
    "\n",
    "df2 = pd.DataFrame({'Professor': ['Zachary Dodds', 'Vatche Sahakian', \n",
    "                                  'Timothy Tsai', 'Brian Shuve'],\n",
    "                    'CourseCode': ['CSCI35', 'PHYS024',  'ENGR156', 'PHYS024']})\n",
    "\n",
    "df1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.merge(df2, df1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Please refer to the documents [here](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.merge.html) and [here](https://pandas.pydata.org/pandas-docs/stable/user_guide/merging.html) to better grasp how and when to use `merge()` function. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Merging dataframes from [Instacart Market Basket Analysis](https://www.kaggle.com/c/instacart-market-basket-analysis/data) dataset:\n",
    "Load the four files into separate dataframes:   \n",
    "`aisles.csv`   \n",
    "`departments.csv`  \n",
    "`products.csv`  \n",
    "`order_products__train.csv`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = 'instacart-market-basket-analysis/'\n",
    "dfa = pd.read_csv(path + 'aisles.csv')\n",
    "dfd = pd.read_csv(path + 'departments.csv')\n",
    "dfp = pd.read_csv(path + 'products.csv')\n",
    "dfo = pd.read_csv(path + 'order_products__train.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Familiarize yourself with the dataframes. Hint: Use `head()`.  \n",
    "Note: You might want to add code cells. Please ask for help unless you already know how to add a code cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get a dataframe consisting of the name of the products along with their aisle names and department names for the order with `order_id` equal to 1.   \n",
    "Note: dataframe must have ***8 rows and only three columns:\n",
    "```'product_name', 'aisle', 'department'```***\n",
    "\n",
    "Hint: \n",
    "- First slice out 8 rows from the order_products dataframe that corresponds with `order_id` equal to 1 and save it in a dataframe.\n",
    "- Use `merge()` multiple times to merge two dataframes at a time starting with the dataset that have a column in common with the dataframe corresponding to 'order_products__train.csv'.\n",
    "- Finally slice out the 3 selective columns: `'product_name', 'aisle', 'department'`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The output should be (8, 3). Please check your code above if you get something else."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Exploring csv files (optional)\n",
    "\n",
    "Dataframes are easily convertible to and from csv (comma seperated text) files. Convert the last dataframe to a csv file using `to_csv()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Instructions for the next steps if using Kaggle kernel:\n",
    "* Commit the kernel so that the output file is generated. You can visit the kernels page (without the \"/edit\" and instead use \"/output\" at the end) in the link to download the output file. Please ask for help if the instructions are not clear. \n",
    "* Open the csv file using MS-Excel, any text editor or other applications of your choice. \n",
    "* Edit the file, save it and upload it to the Kaggle kernel using 'ADD DATASET' option.\n",
    "\n",
    "Instructions for the next steps if using Jupyter Notebook in your laptop:\n",
    "* Go to the folder where Notebook is saved and locate the output file.\n",
    "* Open the csv file using MS-Excel, any text editor or other application of your choice that supports csv files. \n",
    "* Edit the file and save it."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, read the csv file and check whether the changes are reflected."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Acknowledgement:\n",
    "The following datasets openly available in Kaggle are used in the exercises.\n",
    "* [Titanic dataset from Kaggle](https://www.kaggle.com/c/titanic)\n",
    "* [Instacart Market Basket Analysis](https://www.kaggle.com/c/instacart-market-basket-analysis/data)\n",
    "* [Predict Future Sales](https://www.kaggle.com/c/competitive-data-science-predict-future-sales)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Next step:\n",
    "\n",
    "Please pick one or more datasets to explore. Suggestions are given [here](http://www.aashitak.com/ML-Workshops/)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
