{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise notebook for the second session (60 min)\n",
    "\n",
    "This is the exercise notebook for the second session of the [Machine Learning workshop series at Harvey Mudd College](http://www.aashitak.com/ML-Workshops/). It involves some new concepts not covered in the guided session. You are encouraged to work in groups of 2-4 if that helps to speed things up. Please ask for help from the instructor and/or TAs. The session is time-bound, so make sure you are not stuck at a problem for too long before asking for help.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "\n",
    "import warnings\n",
    "warnings.simplefilter('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Feature engineering on the Titanic dataset to create a new column for group size (30 min):\n",
    "\n",
    "The [Titanic dataset](https://www.kaggle.com/c/titanic) has been split into two csv files:    \n",
    "* train.csv: The training set to build your machine learning models. It is provided with the `Survived` column.\n",
    "* test.csv: The test set is not provided with `Survived` column. The aim of the competition is to predict this column, that is whether or not the passengers survived the sinking of the Titanic, using the model you trained.\n",
    "\n",
    "We download both the datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = 'titanic/'\n",
    "train = pd.read_csv(path + 'train.csv') \n",
    "test = pd.read_csv(path + 'test.csv') "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a DataFrame named `df` by concatenating the `train` and `test` datasets one below the other. Hint: Use [`concat()`](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.concat.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Description for the columns](https://www.kaggle.com/c/titanic/data) is as follows.  \n",
    "\n",
    "|Variable|\tDefinition|\tKey|   \n",
    "|:---  |:--- |:---|\n",
    "|PassengerId| Passenger ID |\n",
    "|Survived| \tSurvival|\t0 = No, 1 = Yes |\n",
    "|Pclass\t|Ticket class|\t1 = 1st, 2 = 2nd, 3 = 3rd|\n",
    "|Sex\t|Sex|\t\n",
    "|Age\t|Age in years\t|\n",
    "|SibSp\t|# of siblings / spouses aboard the Titanic\t|\n",
    "|Parch\t|# of parents / children aboard the Titanic\t|\n",
    "|Ticket\t|Ticket number\t|\n",
    "|Fare\t|Passenger fare\t|\n",
    "|Cabin\t|Cabin number\t|\n",
    "|Embarked\t|Port of Embarkation\t|C = Cherbourg, Q = Queenstown, S = Southampton|"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this section, we are going to create a new column called `GroupSize` to get the size of the group for each passenger. We consider groups to be either family members or those traveling on the same ticket. This feature is derived using three columns *SibSp*, *Parch* and *Ticket*. \n",
    "\n",
    "[Notes](https://www.kaggle.com/c/titanic/data) for the two features *SibSp* and *Parch* are as follows.\n",
    "\n",
    "> SibSp: The dataset defines family relations in this way...  \n",
    "Sibling = brother, sister, stepbrother, stepsister  \n",
    "Spouse = husband, wife (mistresses and fiancÃ©s were ignored)\n",
    "> \n",
    "> Parch: The dataset defines family relations in this way...  \n",
    "Parent = mother, father  \n",
    "Child = daughter, son, stepdaughter, stepson  \n",
    "Some children travelled only with a nanny, therefore parch=0 for them.\n",
    "\n",
    "First, create a new column named *Family* by adding the columns *SibSp* and *Parch* and then add 1 to it. Hint: Use `df[\"New_column\"] = df[\"column_1\"] + df[\"column_2\"] + 1`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we check the survival rates with respect to the family size."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.barplot(x='Family', y='Survived', data=df);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some passengers that appear to be traveling alone by account of their family size were part of a group traveling on the same ticket. To see this, get all the passengers traveling on the ticket \"1601\" (there are 8 of them)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One can check that there are many tickets shared among passengers that may or may not be family members."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Ticket'].value_counts()[:15]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a new column named *TicketCount* that counts the total number of passengers traveling in each passengers' ticket.\n",
    "\n",
    "Hint: \n",
    "- First group passengers based on their tickets using `groupby()` on the *Ticket* column.\n",
    "- For the grouped object, pick any column that has no missing values.\n",
    "- Use `transform()` for this unique identifier column with the function `\"count\"` to create a new column *TicketCount*.\n",
    "\n",
    "For example, we created *MedianAge* using the following code:   \n",
    "```df['MedianAge'] = df.groupby('Title')['Age'].transform(\"median\")```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot the survival rates based on the *TicketCount* using `sns.barplot()` (see above)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It does seem that the number of co-travelers have an impact on the survival rates."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a new column named *GroupSize* by picking the maximum value among the columns *Family* and *TicketCount*.   \n",
    "Note: We consider groups to be either family members or those traveling on the same ticket.   \n",
    "Hint: Use built-in `max()` function for pandas on the two relevant columns with the appropriate value for the `axis` parameter. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot the survival rates based on the *GroupSize* using `sns.barplot()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check the number of rows where *Groupsize* is not equal to *Family*. Similarly, check the number of rows where *TicketCount* is not equal to *Family*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df['GroupSize'] != df['Family']].shape[0], \n",
    "df[df['GroupSize'] != df['TicketCount']].shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The output must be `(200, 84)`. Check your above code, if you get a different output."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Creating a new column using grouping on two columns of [Predict Future Sales](https://www.kaggle.com/c/competitive-data-science-predict-future-sales) dataset (10 min):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = 'competitive-data-science-predict-future-sales/'\n",
    "df = pd.read_csv(path + 'sales_train.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[The description](https://www.kaggle.com/c/competitive-data-science-predict-future-sales/data) for each of the following columns is as follows. \n",
    "- date: date in format dd/mm/yyyy\n",
    "- date_block_num: a consecutive month number, used for convenience. January 2013 is 0, February 2013 is 1,..., October 2015 is 33\n",
    "- shop_id: unique identifier of a shop\n",
    "- item_id: unique identifier of a product\n",
    "- item_price: current price of an item\n",
    "- item_cnt_day: number of products sold\n",
    "       \n",
    "The aim of the competition is to predict the monthly sales. We are given the daily sales of items in each shop in the column *item_cnt_day*. We want to create a new column named *item_cnt_monthly* that gives the monthly sales of the items using the columns *item_cnt_day* and *date_block_num*. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Currently, the rows are sorted based on the *date* column. We want them sorted first w.r.t. *date_block_num* and then  w.r.t. *item_id* within each *date_block_num*. Hint: Use `sort_values()` on the two columns: `'date_block_num','item_id'`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We sorted the rows so that it will make it easier to check whether our code below is working correctly. For the *date_block_num* equal to 0, we can see that the item with *item_id* 19 is sold once, one with *item_id* 27 is sold 7 times and so on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can use `groupby()` on the two columns - *date_block_num* and *item_id* and sum the values in the *item_cnt_day* column in each grouping as follows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.groupby(['date_block_num', 'item_id'])['item_cnt_day'].sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a new column named *item_cnt_monthly* that gives the monthly sales of the items\n",
    "\n",
    "Hint: Use `transform()` with the function `\"sum\"` along with `groupby()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check that the code indeed worked as expected."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head(25)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Merging columns from different datasets (20 min):"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A simple illustration to merge two datasets using `merge()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = pd.DataFrame({'CourseCode': ['PHYS024', 'CSCI35', 'ENGR156'], \n",
    "                   'CourseName': ['Mechanics and Wave Motion', \n",
    "                                  'Computer Science for Insight',\n",
    "                                 'Intro to Comm & Info Theory']})\n",
    "\n",
    "df2 = pd.DataFrame({'Professor': ['Zachary Dodds', 'Vatche Sahakian', \n",
    "                                  'Timothy Tsai', 'Brian Shuve'],\n",
    "                    'CourseCode': ['CSCI35', 'PHYS024',  'ENGR156', 'PHYS024']})\n",
    "\n",
    "df1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.merge(df2, df1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Please refer to the documents [here](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.merge.html) and [here](https://pandas.pydata.org/pandas-docs/stable/user_guide/merging.html) to better grasp how and when to use `merge()` function. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Merging dataframes from [Instacart Market Basket Analysis](https://www.kaggle.com/c/instacart-market-basket-analysis/data) dataset:\n",
    "Load the four files into separate dataframes:   \n",
    "`aisles.csv`   \n",
    "`departments.csv`  \n",
    "`products.csv`  \n",
    "`order_products__train.csv`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = 'instacart-market-basket-analysis/'\n",
    "dfa = pd.read_csv(path + 'aisles.csv')\n",
    "dfd = pd.read_csv(path + 'departments.csv')\n",
    "dfp = pd.read_csv(path + 'products.csv')\n",
    "dfo = pd.read_csv(path + 'order_products__train.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Familiarize yourself with the dataframes. Hint: Use `head()`.  \n",
    "Note: You might want to add code cells. Please ask for help unless you already know how to add a code cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get a dataframe consisting of the name of the products along with their aisle names and department names for the order with `order_id` equal to 1.   \n",
    "Note: dataframe must have ***8 rows and only three columns:\n",
    "```'product_name', 'aisle', 'department'```***\n",
    "\n",
    "Hint: \n",
    "- First slice out 8 rows from the order_products dataframe that corresponds with `order_id` equal to 1 and save it in a dataframe.\n",
    "- Use `merge()` multiple times to merge two dataframes at a time starting with the dataset that have a column in common with the dataframe corresponding to 'order_products__train.csv'.\n",
    "- Finally slice out the 3 selective columns: `'product_name', 'aisle', 'department'`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The output should be (8, 3). Please check your code above if you get something else."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Exploring csv files (optional)\n",
    "\n",
    "Dataframes are easily convertible to and from csv (comma seperated text) files. Convert the last dataframe to a csv file using `to_csv()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Instructions for the next steps if using Kaggle kernel:\n",
    "* Commit the kernel so that the output file is generated. You can visit the kernels page (without the \"/edit\" and instead use \"/output\" at the end) in the link to download the output file. Please ask for help if the instructions are not clear. \n",
    "* Open the csv file using MS-Excel, any text editor or other applications of your choice. \n",
    "* Edit the file, save it and upload it to the Kaggle kernel using 'ADD DATASET' option.\n",
    "\n",
    "Instructions for the next steps if using Jupyter Notebook in your laptop:\n",
    "* Go to the folder where Notebook is saved and locate the output file.\n",
    "* Open the csv file using MS-Excel, any text editor or other application of your choice that supports csv files. \n",
    "* Edit the file and save it."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, read the csv file and check whether the changes are reflected."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Acknowledgement:\n",
    "The following datasets openly available in Kaggle are used in the exercises.\n",
    "* [Titanic dataset from Kaggle](https://www.kaggle.com/c/titanic)\n",
    "* [Instacart Market Basket Analysis](https://www.kaggle.com/c/instacart-market-basket-analysis/data)\n",
    "* [Predict Future Sales](https://www.kaggle.com/c/competitive-data-science-predict-future-sales)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Next step:\n",
    "\n",
    "Please pick one or more datasets to explore. Suggestions are given [here](http://www.aashitak.com/ML-Workshops/).\n",
    "\n",
    "**Note:**\n",
    "The solutions for this exercise can be found [here](https://github.com/AashitaK/ML-Workshops/blob/master/Session%202/Exercise%202%20with%20solutions.ipynb)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
