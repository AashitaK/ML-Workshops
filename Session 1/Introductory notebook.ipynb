{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Introduction\n",
    "\n",
    "What do we mean by Machine Learning?\n",
    "- Learning from data and finding patterns without being explicity programmed. \n",
    "\n",
    "Three broad categories:\n",
    "- Supervised learning\n",
    "- Unsupervised learning\n",
    "- Reinforcement learning - learning by maximizing a reward function, for example training of self-driving from using feedback from the environment.\n",
    "\n",
    "In this workshop, we will be focusing on the two supervised learning tasks: \n",
    "- Classification \n",
    "- Regression\n",
    "\n",
    "How to approach a problem? Broadly two parts:\n",
    "- Data exploration and feature engineering\n",
    "- Model building, tuning and testing  \n",
    "\n",
    "### Today's session\n",
    "Topics to be covered today:  \n",
    "- Pandas dataframes as the data structure for datasets\n",
    "- Converting csv files to dataframes \n",
    "- Slicing and indexing dataframes using conditionals as well as iloc and loc methods.\n",
    "- Statistical summary and exploration of dataframes\n",
    "- Detecting and filling missing values in the dataframes \n",
    "- Regular expressions for data extraction\n",
    "- Feature engineering such as creating new features \n",
    "- Basic plots\n",
    "- Correlation among features\n",
    "- Basic operations such as dropping rows/columns, setting index, replacing values of a column using a dictionary, etc.\n",
    "\n",
    "Structure for today's workshop:\n",
    "- Introduction (20 min)\n",
    "- Guided session (30 min)\n",
    "- Hands-on exercise (45 min)\n",
    "- Project work (20 min)\n",
    "\n",
    "At the end, you will pick a dataset that you will be working on in the consecutive sessions. It would be great to work on datasets in-between the sessions and afterwards as and when you find time. You are also encouraged to explore multiple datasets instead of just one.\n",
    "\n",
    "Let us start with the guided session. Please find the links below:\n",
    "- Guided session 1\n",
    "- Exercise 1\n",
    "\n",
    "We recommend using Kaggle Kernels - cloud computation platform from Kaggle - for the guided session and exercise. Please use the above links and fork the notebooks and work with them. If you want to use your own laptop, please download the material from the [Github repository for the workshop](https://github.com/AashitaK/ML-Workshops) and install Jupyter notebook using Anaconda installation.  Please ask for help from anyone of us, if you run into trouble with running the notebooks."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Picking a dataset\n",
    "If you are complete begineer with limited time to spare, these two datasets are a great choice to learn from with minimal effort. You can pick both, one for classification and other for regression.\n",
    "* [Titanic: Machine Learning from Disaster](https://www.kaggle.com/c/titanic)\n",
    "* [House Prices: Predict sales prices](https://www.kaggle.com/c/house-prices-advanced-regression-techniques)  \n",
    "\n",
    "If you are a beginner willing to dive in and be changelled, these are some good ones:\n",
    "* [Predict Future Sales](https://www.kaggle.com/c/competitive-data-science-predict-future-sales)\n",
    "* [Bike Sharing Demand](https://www.kaggle.com/c/bike-sharing-demand/data)\n",
    "\n",
    "These datasets are great if you can bear with the initial frustation of finding your way and willing to put in time and effort: \n",
    "* [New York City Taxi Trip Duration](https://www.kaggle.com/c/nyc-taxi-trip-duration/data)\n",
    "* [New York City Taxi Fare Prediction](https://www.kaggle.com/c/new-york-city-taxi-fare-prediction)\n",
    "* [Reducing Commercial Aviation Fatalities](https://www.kaggle.com/c/reducing-commercial-aviation-fatalities/data)\n",
    "* [Instacart Market Basket Analysis](https://www.kaggle.com/c/instacart-market-basket-analysis/data)\n",
    "* [Mercari Price Suggestion Challenge](https://www.kaggle.com/c/mercari-price-suggestion-challenge/data)\n",
    "\n",
    "The list is not exhaustive. [Kaggle Competitions](https://www.kaggle.com/competitions) (past and current) as well as [Kaggle Datasets](https://www.kaggle.com/datasets) are an excellent resource to find datasets. Below are a few suggestions to note if you want to pick a dataset from outside the above list:\n",
    "* Data must be in tabular format (csv files). We will cover other data formats in Deep Learning workshop series later on. Please donâ€™t pick tabular data stored in Google BigQuery format as it is usually too  big to work with.\n",
    "* Prefer past competitions that have a high participation, a lot of shared kernels and many topics in the discussion forum to learn from.\n",
    "* Main features must not be textual unless you already know or plan to learn some natural language processing concepts within the time frame.\n",
    "* Data size must be manageable with respect to the computation power you have access to, especially important to check for the recent competitions. You can also run notebooks in [Google Colab](https://research.google.com/colaboratory/faq.html) for free.\n",
    "* It is better to pick a [competition dataset](https://www.kaggle.com/competitions) than one from the [dataset archive](https://www.kaggle.com/datasets) unless you have an idea about how to formulate the problem and choose evaluation metrics. Must check with a quick baseline model that the performance is not inappreciable for the formulated problem with respect to the decided metrics. \n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
