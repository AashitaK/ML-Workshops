{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Meet the Instructor:\n",
    "Aashita Kesarwani  \n",
    "Current job: Scientific Computing Specialist at Harvey Mudd College  \n",
    "Background:  \n",
    "- PhD in Mathematics from Tulane University (Number Theory)\n",
    "- Undergraduate from IIT (Indian Institute of Technology) in Applied Math with CS minor  \n",
    "\n",
    "Other roles: \n",
    "- Visiting AI Researcher at [deepkapha.ai](https://www.linkedin.com/company/digitalis-kapha-b-v-/)\n",
    "- Technical Reviewer, Deep Learning for Natural Language Processing course by [Packt](https://www.packtpub.com/)\n",
    "- [Open source contributor](https://pypi.org/user/Aashita/)\n",
    "\n",
    "### Meet the TAs:\n",
    "- Rex Asabor: \n",
    "Hi, my name is Rex! I am from Long Island, New York and am a freshman Computer Science major here at Harvey Mudd. As for my background in ML, I interned at The Jackson Laboratory last summer and designed a logistic regression machine learning model to locate corresponding genes in mouse strains. This summer I will be interning as a Software Engineer at a small hedge fund in Houston. I am excited to explore machine learning with you all during this series!\n",
    "\n",
    "- Ben Langton:\n",
    "Hi, I’m Ben, a Mudd freshman planning to do a joint Math/CS major. I am very interested in machine learning and data science. A cool project I am currently working on is building a chatbot with conversational data and deep learning models.\n",
    "\n",
    "- Qualan Woodard:\n",
    "Hi I'm Qualan, a freshman at HMC who plans to major in Comp sci/math. I am really interested in machine learning and have experience working on various machine learning projects. Something cool I have done is teach an agent to play pong against a human player using a version of reinforcement learning called Deep Q Learning. I am excited to help you all learn a bit more about ML and start your own interesting projects.\n",
    "\n",
    "### Introduction\n",
    "\n",
    "What do we mean by Machine Learning?\n",
    "- Learning from data and finding patterns without being explicity programmed. \n",
    "\n",
    "Three broad categories:\n",
    "- Supervised learning\n",
    "- Unsupervised learning\n",
    "- Reinforcement learning - learning by maximizing a reward function, for example training of self-driving car from using feedback from the environment.\n",
    "\n",
    "In this workshop, we will be focusing on the two supervised learning tasks: \n",
    "- Classification \n",
    "- Regression\n",
    "\n",
    "How to approach a problem? Broadly two parts:\n",
    "- Data exploration and feature engineering\n",
    "- Model building, tuning and testing  \n",
    "\n",
    "### Today's session\n",
    "Topics to be covered today:  \n",
    "- Pandas dataframes as the data structure for datasets\n",
    "- Converting csv files to dataframes \n",
    "- Slicing and indexing dataframes using conditionals as well as iloc and loc methods.\n",
    "- Statistical summary and exploration of dataframes\n",
    "- Detecting and filling missing values in the dataframes \n",
    "- Regular expressions for data extraction\n",
    "- Feature engineering such as creating new features \n",
    "- Basic plots\n",
    "- Correlation among features\n",
    "- Basic operations such as dropping rows/columns, setting index, replacing values of a column using a dictionary, etc.\n",
    "\n",
    "Structure for today's workshop:\n",
    "- Introduction (20 min)\n",
    "- Guided session (30 min)\n",
    "- Hands-on exercise (50 min)\n",
    "- Project work (15 min)\n",
    "\n",
    "At the end, you will pick a dataset that you will be working on in the consecutive sessions. It would be great to work on datasets in-between the sessions and afterwards when you find time. You are also encouraged to explore multiple datasets instead of just one.\n",
    "\n",
    "Let us start with the guided session. Please find the links below:\n",
    "- [Guided session 1](https://github.com/AashitaK/ML-Workshops/blob/master/Session%201/Guided%20session%201.ipynb)\n",
    "- [Hands-on Exercise 1](https://github.com/AashitaK/ML-Workshops/blob/master/Session%201/Exercise%201.ipynb)\n",
    "\n",
    "We recommend using Kaggle Kernels - cloud computation platform from Kaggle - for the guided session and exercise. Please use the above links and fork the notebooks and work with them. If you want to use your own laptop, please download the material from the [Github repository for the workshop](https://github.com/AashitaK/ML-Workshops) and install Jupyter notebook using Anaconda installation.  Please ask for help from anyone of us, if you run into trouble with running the notebooks."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Picking a dataset\n",
    "If you are complete begineer with limited time to spare, these two datasets are a great choice to learn from with minimal effort. You can pick both, one for classification and other for regression.\n",
    "* [Titanic: Machine Learning from Disaster](https://www.kaggle.com/c/titanic)\n",
    "* [House Prices: Predict sales prices](https://www.kaggle.com/c/house-prices-advanced-regression-techniques)  \n",
    "\n",
    "If you are a beginner willing to dive in and be changelled, here are some good ones:\n",
    "* [Predict Future Sales](https://www.kaggle.com/c/competitive-data-science-predict-future-sales)\n",
    "* [Bike Sharing Demand](https://www.kaggle.com/c/bike-sharing-demand/data)\n",
    "\n",
    "These datasets are great if you can bear with the initial frustation of finding your way and willing to put in time and effort: \n",
    "* [New York City Taxi Trip Duration](https://www.kaggle.com/c/nyc-taxi-trip-duration/data)\n",
    "* [New York City Taxi Fare Prediction](https://www.kaggle.com/c/new-york-city-taxi-fare-prediction)\n",
    "* [Reducing Commercial Aviation Fatalities](https://www.kaggle.com/c/reducing-commercial-aviation-fatalities/data)\n",
    "* [Instacart Market Basket Analysis](https://www.kaggle.com/c/instacart-market-basket-analysis/data)\n",
    "* [Mercari Price Suggestion Challenge](https://www.kaggle.com/c/mercari-price-suggestion-challenge/data)\n",
    "\n",
    "The list is not exhaustive. [Kaggle Competitions](https://www.kaggle.com/competitions) (past and current) as well as [Kaggle Datasets](https://www.kaggle.com/datasets) are an excellent resource to find datasets. Below are a few suggestions to note if you want to pick a dataset from outside the above list:\n",
    "* Data must be in tabular format (csv files). We will cover other data formats in Deep Learning workshop series later on. Please don’t pick tabular data stored in Google BigQuery format as it is usually too  big to work with.\n",
    "* Prefer past competitions that have a high participation, a lot of shared kernels and many topics in the discussion forum to learn from.\n",
    "* Main features must not be textual unless you already know or plan to learn some natural language processing concepts within the time frame.\n",
    "* Data size must be manageable with respect to the computation power you have access to, especially important to check for the recent competitions. You can also run notebooks in [Google Colab](https://research.google.com/colaboratory/faq.html) for free.\n",
    "* It is better to pick a [competition dataset](https://www.kaggle.com/competitions) than one from the [dataset archive](https://www.kaggle.com/datasets) unless you have an idea about how to formulate the problem and choose evaluation metrics. Must check with a quick baseline model that the performance is not inappreciable for the formulated problem with respect to the decided metrics. \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Useful links:\n",
    "- You are also welcome to join our google group [HMC Machine Learning](https://groups.google.com/forum/#!forum/hmc-machine-learning) that we plan to use for the workshop as well as future activities.\n",
    "- We recommend installing Python and Jupyter Notebook using the [Anaconda Distribution](https://www.anaconda.com/distribution/) for using Notebooks in your laptop."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
