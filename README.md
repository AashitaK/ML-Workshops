### Introduction:

The workshop series is designed with a focus on the practical aspects of machine learning. We will be working in Python and using real-world datasets from [Kaggle](https://www.kaggle.com), the machine learning platform most suited for the “learn by doing” philosophy. The series is targeted towards complete beginners familiar with Python, but it is also designed adaptively so that you will be challenged even if you have some familiarity with machine learning tools. 


The four-session workshop is going to be very hands-on and will focus on how to work with datasets. Instead of comprehensively covering every tool and concept, you will learn the minimal but most useful tools and concepts quickly and how to find other resources to explore further.  

Timeline:  
Session 1: 5:30-7:30 pm on Thursday March 28, 2019 at Aviation Room, HMC   
Session 2: 5:30-7:30 pm on Thursday April 4, 2019 at Shan 2454, HMC   
Session 3: 5:30-7:30 pm on Thursday April 11, 2019 at Aviation Room, HMC    
Session 4: 5:30-7:30 pm on Thursday April 18, 2019 at Shan 2454, HMC   

This series is a precursor to a future Deep Learning workshop series. 

### General structure of each two-hour session in the workshop series:
* Guided session
* Hands-on exercise
* Project work

Four sessions are planned in the series with the following time allocations:

| Sessions | Guided session (min) | Hands-on exercise (min) | Project work (min) | Total time (min) |
|----------|:----------:|:----------:|:----------:|:----------------:|
| 1 | 50 | 70 | - | 120 |
| 2 | 30 | 80 | 10 | 120 |
| 3 | 30 | 50  | 40 | 120 |
| 4 | 30 | 60 | 30 | 120 |

### Topics covered in the guided sessions and hands-on exercises:  
Session 1: Exploratory Data Analysis and Feature Engineering using Pandas - 1
- Pandas dataframes as the data structure for datasets
- Converting csv files to dataframes 
- Slicing and indexing dataframes using conditionals as well as iloc and loc methods.
- Statistical summary and exploration of dataframes
- Detecting and filling missing values in the dataframes 
- Regular expressions for data extraction
- Feature engineering such as creating new features 
- Basic plots
- Correlation among features
- Basic operations such as dropping rows/columns, setting index, replacing values of a column using a dictionary, etc.

Session 2: Exploratory Data Analysis and Feature Engineering using Pandas - 2
- Split-apply-combine operations by grouping rows of a dataframe 
- Encoding categorical variables 
- Concatentating and merging dataframes 
- More operations such as sorting the rows, creating a dataframe from the scratch, etc. 

Session 3: Model Building, Tuning and Testing using Scikit-learn - 1
- Overfitting and underfitting of models
- Regression algorithms 
    - Linear regression
    - Polynomial regression
    - Rigde regression
    - Lasso regression
    - Elastic Net regression
- Model validation
- Hypertuning regularization paramter
- Hypertuning learning rate
- Evaluation metrics for regression - R-squared and root mean-squared error (RMSE)
- Normalization and scaling of features
    
Session 4: Model Building, Tuning and Testing using Scikit-learn - 2
- Classification algorithms 
    - Logistic regression
    - Decision trees
    - k-nearest neighbors
    - Support vector machines
    - Random forests
- Evaluation metrics for classification - accuracy, precision, recall, F-1 score, ROC curve, etc.
- Dimensionality reduction techniques such as Principal Component Analysis (PCA), etc.
- Bootstrapping models
- k-fold cross-validation

### Pre-requisites:
* Python programming basics (HMC CS-5 or equivalent should suffice)
* Some familiarity with common statistical concepts (HMC MATH-35 or equivalent should suffice)

It will be beyond the scope of the workshop series to cover the theory and mathematics behind the machine learning algorithms in depth and participants are encouraged to learn them on their own and deepen their understanding. A gentle and intuitive introduction will be covered in the workshop series and resource links will be given for self-study. The focus will be on the practical aspects of machine learning and the concepts like feature engineering, overfitting vs underfitting, cross-validation, etc. that are crucial for all varieties of machine learning algorithms, including deep neural networks that will be covered in a future Deep Learning series.

### Learning materials:
The learning material is shared on [Github](https://github.com/AashitaK/ML-Workshops) and is updated after every session. The material is designed to be self-sufficient and useful in case you miss a session. 

### Team:
Instructor: Aashita Kesarwani  
TAs: Rex Asabor, Ben Langton and Qualan Woodard


Seats are limited, please register using [this link](https://forms.gle/wFA1q9eqG3hgn2xN6). It is important that you attend all four sessions of the series for it to be useful.
