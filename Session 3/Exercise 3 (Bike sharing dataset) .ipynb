{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise notebook for the third session (30 min)\n",
    "\n",
    "This is the exercise notebook for the third session of the [Machine Learning workshop series at Harvey Mudd College](http://www.aashitak.com/ML-Workshops/). Please feel free to ask for help from the instructor and/or TAs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First we import python modules:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression, Lasso, Ridge, ElasticNet\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "\n",
    "import warnings\n",
    "warnings.simplefilter('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we will tackle the [Bike Sharing Demand](https://www.kaggle.com/c/bike-sharing-demand/overview) dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>datetime</th>\n",
       "      <th>season</th>\n",
       "      <th>holiday</th>\n",
       "      <th>workingday</th>\n",
       "      <th>weather</th>\n",
       "      <th>temp</th>\n",
       "      <th>atemp</th>\n",
       "      <th>humidity</th>\n",
       "      <th>windspeed</th>\n",
       "      <th>casual</th>\n",
       "      <th>registered</th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2011-01-01 00:00:00</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>9.84</td>\n",
       "      <td>14.395</td>\n",
       "      <td>81</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3</td>\n",
       "      <td>13</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2011-01-01 01:00:00</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>9.02</td>\n",
       "      <td>13.635</td>\n",
       "      <td>80</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8</td>\n",
       "      <td>32</td>\n",
       "      <td>40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2011-01-01 02:00:00</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>9.02</td>\n",
       "      <td>13.635</td>\n",
       "      <td>80</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5</td>\n",
       "      <td>27</td>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2011-01-01 03:00:00</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>9.84</td>\n",
       "      <td>14.395</td>\n",
       "      <td>75</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2011-01-01 04:00:00</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>9.84</td>\n",
       "      <td>14.395</td>\n",
       "      <td>75</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              datetime  season  holiday  workingday  weather  temp   atemp  \\\n",
       "0  2011-01-01 00:00:00       1        0           0        1  9.84  14.395   \n",
       "1  2011-01-01 01:00:00       1        0           0        1  9.02  13.635   \n",
       "2  2011-01-01 02:00:00       1        0           0        1  9.02  13.635   \n",
       "3  2011-01-01 03:00:00       1        0           0        1  9.84  14.395   \n",
       "4  2011-01-01 04:00:00       1        0           0        1  9.84  14.395   \n",
       "\n",
       "   humidity  windspeed  casual  registered  count  \n",
       "0        81        0.0       3          13     16  \n",
       "1        80        0.0       8          32     40  \n",
       "2        80        0.0       5          27     32  \n",
       "3        75        0.0       3          10     13  \n",
       "4        75        0.0       0           1      1  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path = 'bike-sharing-demand/'\n",
    "rides = pd.read_csv(path + 'train.csv')\n",
    "rides.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Data Fields**\n",
    "\n",
    "* datetime - hourly date + timestamp    \n",
    "* season -  1 = spring, 2 = summer, 3 = fall, 4 = winter   \n",
    "* holiday - whether the day is considered a holiday  \n",
    "* workingday - whether the day is neither a weekend nor holiday  \n",
    "* weather -   \n",
    "    1: Clear, Few clouds, Partly cloudy, Partly cloudy   \n",
    "    2: Mist + Cloudy, Mist + Broken clouds, Mist + Few clouds, Mist   \n",
    "    3: Light Snow, Light Rain + Thunderstorm + Scattered clouds, Light Rain + Scattered clouds   \n",
    "    4: Heavy Rain + Ice Pallets + Thunderstorm + Mist, Snow + Fog   \n",
    "* temp - temperature in Celsius  \n",
    "* atemp - \"feels like\" temperature in Celsius  \n",
    "* humidity - relative humidity  \n",
    "* windspeed - wind speed  \n",
    "* casual - number of non-registered user rentals initiated  \n",
    "* registered - number of registered user rentals initiated  \n",
    "* count - number of total rentals  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us look at the *datetime* values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['2011-01-01 00:00:00', '2011-01-01 01:00:00',\n",
       "       '2011-01-01 02:00:00', '2011-01-01 03:00:00',\n",
       "       '2011-01-01 04:00:00'], dtype=object)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rides['datetime'].values[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we perform some feature engineering and data pre-processing similar to what we practised in the previous two sessions. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "# We extract 'month', 'hour', 'weekday' from the 'datetime' column\n",
    "def extract_from_datetime(rides):\n",
    "    rides[\"date\"] = rides[\"datetime\"].apply(lambda x : x.split()[0])\n",
    "    rides[\"hour\"] = rides[\"datetime\"].apply(lambda x : x.split()[1].split(\":\")[0])\n",
    "    rides[\"weekday\"] = rides[\"date\"].apply(lambda dateString : \n",
    "                            datetime.strptime(dateString,\"%Y-%m-%d\").weekday())\n",
    "    rides[\"month\"] = rides[\"date\"].apply(lambda dateString : \n",
    "                            datetime.strptime(dateString,\"%Y-%m-%d\").month)\n",
    "    return rides\n",
    "\n",
    "# We one-hot encode the categorical features\n",
    "def one_hot_encoding(rides):\n",
    "    dummy_fields = ['season', 'weather', 'month', 'hour', 'weekday']\n",
    "    for each in dummy_fields:\n",
    "        dummies = pd.get_dummies(rides[each], prefix=each, drop_first=False)\n",
    "        rides = pd.concat([rides, dummies], axis=1)\n",
    "    return rides\n",
    "\n",
    "# We drop the columns that are redundant now\n",
    "def drop_features(rides):\n",
    "    features_to_drop = ['datetime', 'date', \n",
    "                        'month', 'hour', 'weekday', \n",
    "                        'season', 'weather']\n",
    "\n",
    "    rides = rides.drop(features_to_drop, axis=1)\n",
    "    return rides\n",
    "\n",
    "# Now we aggregate all the above defined functions inside a function\n",
    "def feature_engineering(rides):\n",
    "    rides = extract_from_datetime(rides)\n",
    "    rides = one_hot_encoding(rides)\n",
    "    rides = drop_features(rides)\n",
    "    return rides\n",
    "\n",
    "# Now we apply all the above defined functions to the rides dataframe\n",
    "rides = feature_engineering(rides)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The reason we defined all the steps as functions and bundled them into another function `feature_engineering` is so as to reuse the code for processing the data from `test.csv` file for which we will make predictions at the end."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>holiday</th>\n",
       "      <th>workingday</th>\n",
       "      <th>temp</th>\n",
       "      <th>atemp</th>\n",
       "      <th>humidity</th>\n",
       "      <th>windspeed</th>\n",
       "      <th>casual</th>\n",
       "      <th>registered</th>\n",
       "      <th>count</th>\n",
       "      <th>season_1</th>\n",
       "      <th>...</th>\n",
       "      <th>hour_21</th>\n",
       "      <th>hour_22</th>\n",
       "      <th>hour_23</th>\n",
       "      <th>weekday_0</th>\n",
       "      <th>weekday_1</th>\n",
       "      <th>weekday_2</th>\n",
       "      <th>weekday_3</th>\n",
       "      <th>weekday_4</th>\n",
       "      <th>weekday_5</th>\n",
       "      <th>weekday_6</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>9.84</td>\n",
       "      <td>14.395</td>\n",
       "      <td>81</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3</td>\n",
       "      <td>13</td>\n",
       "      <td>16</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>9.02</td>\n",
       "      <td>13.635</td>\n",
       "      <td>80</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8</td>\n",
       "      <td>32</td>\n",
       "      <td>40</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>9.02</td>\n",
       "      <td>13.635</td>\n",
       "      <td>80</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5</td>\n",
       "      <td>27</td>\n",
       "      <td>32</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>9.84</td>\n",
       "      <td>14.395</td>\n",
       "      <td>75</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>13</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>9.84</td>\n",
       "      <td>14.395</td>\n",
       "      <td>75</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 60 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   holiday  workingday  temp   atemp  humidity  windspeed  casual  registered  \\\n",
       "0        0           0  9.84  14.395        81        0.0       3          13   \n",
       "1        0           0  9.02  13.635        80        0.0       8          32   \n",
       "2        0           0  9.02  13.635        80        0.0       5          27   \n",
       "3        0           0  9.84  14.395        75        0.0       3          10   \n",
       "4        0           0  9.84  14.395        75        0.0       0           1   \n",
       "\n",
       "   count  season_1    ...      hour_21  hour_22  hour_23  weekday_0  \\\n",
       "0     16         1    ...            0        0        0          0   \n",
       "1     40         1    ...            0        0        0          0   \n",
       "2     32         1    ...            0        0        0          0   \n",
       "3     13         1    ...            0        0        0          0   \n",
       "4      1         1    ...            0        0        0          0   \n",
       "\n",
       "   weekday_1  weekday_2  weekday_3  weekday_4  weekday_5  weekday_6  \n",
       "0          0          0          0          0          1          0  \n",
       "1          0          0          0          0          1          0  \n",
       "2          0          0          0          0          1          0  \n",
       "3          0          0          0          0          1          0  \n",
       "4          0          0          0          0          1          0  \n",
       "\n",
       "[5 rows x 60 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rides.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['holiday', 'workingday', 'temp', 'atemp', 'humidity', 'windspeed',\n",
       "       'casual', 'registered', 'count', 'season_1', 'season_2', 'season_3',\n",
       "       'season_4', 'weather_1', 'weather_2', 'weather_3', 'weather_4',\n",
       "       'month_1', 'month_2', 'month_3', 'month_4', 'month_5', 'month_6',\n",
       "       'month_7', 'month_8', 'month_9', 'month_10', 'month_11', 'month_12',\n",
       "       'hour_00', 'hour_01', 'hour_02', 'hour_03', 'hour_04', 'hour_05',\n",
       "       'hour_06', 'hour_07', 'hour_08', 'hour_09', 'hour_10', 'hour_11',\n",
       "       'hour_12', 'hour_13', 'hour_14', 'hour_15', 'hour_16', 'hour_17',\n",
       "       'hour_18', 'hour_19', 'hour_20', 'hour_21', 'hour_22', 'hour_23',\n",
       "       'weekday_0', 'weekday_1', 'weekday_2', 'weekday_3', 'weekday_4',\n",
       "       'weekday_5', 'weekday_6'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rides.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10886, 60)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rides.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For all algorithms using gradient descent for minimizing the cost function, normalizing features helps speed up the learning process. This is because otherwise the features with values higher in magnitudes will dominate the updates. See [here](https://www.coursera.org/lecture/machine-learning/gradient-descent-in-practice-i-feature-scaling-xx3Da) and [here](https://gist.github.com/oskarth/3469833). We substract the qunatitative features by their mean and divide by their standard deviation to redistribute them to have mean 0 and standard deviation 1. \n",
    "$$ x' = \\frac{x - \\mu}{\\sigma} $$\n",
    "![](https://www.jeremyjordan.me/content/images/2018/01/Screen-Shot-2018-01-23-at-2.27.20-PM.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "quantitative_features = ['temp', 'atemp', 'humidity', 'windspeed']\n",
    "\n",
    "# Store scalings in a dictionary so we can convert back later\n",
    "scaled_features = {}\n",
    "for each in quantitative_features:\n",
    "    mean, std = rides[each].mean(), rides[each].std()\n",
    "    scaled_features[each] = [mean, std]\n",
    "    rides.loc[:, each] = (rides[each] - mean)/std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Next we extract the target variables from the dataframe\n",
    "target = rides[['casual', 'registered', 'count']]\n",
    "target = np.log1p(target)\n",
    "rides = rides.drop(['casual', 'registered', 'count'], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First we split the data into training and validation set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_valid, y_train, y_valid = train_test_split(rides, target,\n",
    "                                        random_state = 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train a linear regression model using the training set and calculate the $R^2$ score for both training and validation set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R-squared score (training): 0.809\n",
      "R-squared score (validation): 0.803\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You should get the following $R^2$ values for the training and validation set.  \n",
    "`R-squared score (training): 0.641\n",
    "R-squared score (validation): 0.625`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us try polynomial regression with degree 2. First we get polynomial features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "poly2 = PolynomialFeatures(degree=2)\n",
    "X_poly2 = poly2.fit_transform(rides)\n",
    "X_train_poly2, X_valid_poly2, y_train_poly2, y_valid_poly2 = train_test_split(X_poly2, \n",
    "                                                    target['count'], random_state = 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train a polynomial regression model using [`LinearRegression()`](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LinearRegression.html) on polynomial features and call it `polyreg2`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R-squared score (training): 0.944\n",
      "R-squared score (validation): 0.929\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train a polynomial regression coupled with Ridge and call it `polyreg2_ridge`. Tune the regularization parameter alpha."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R-squared score (training): 0.942\n",
      "R-squared score (validation): 0.929\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train a polynomial regression coupled with Lasso and call it `polyreg2_lasso`. Tune the regularization parameter alpha."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R-squared score (training): 0.000\n",
      "R-squared score (validation): -0.000\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let us try polynomial regression with degree 3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "poly3 = PolynomialFeatures(degree=3)\n",
    "X_poly3 = poly3.fit_transform(rides)\n",
    "X_train_poly3, X_valid_poly3, y_train_poly3, y_valid_poly3 = train_test_split(X_poly3, \n",
    "                                                    target['count'], random_state = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R-squared score (training): 0.988\n",
      "R-squared score (validation): -459154154.311\n"
     ]
    }
   ],
   "source": [
    "polyreg3 = LinearRegression().fit(X_train_poly3, y_train_poly3)\n",
    "\n",
    "polyreg3_train_score = polyreg3.score(X_train_poly3, y_train_poly3)\n",
    "polyreg3_valid_score = polyreg3.score(X_valid_poly3, y_valid_poly3)\n",
    "\n",
    "print('R-squared score (training): {:.3f}'\n",
    "     .format(polyreg3_train_score))\n",
    "print('R-squared score (validation): {:.3f}'\n",
    "     .format(polyreg3_valid_score))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This suggests the model has overfitted to the training set excessively. Nonetheless, the very high $R^2$ looks promising, so we use regularization on the the polynomial regression with degree 3 features. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train the polynomial regression for degree 3 coupled with Ridge and call it `polyreg3_ridge`. Tune the regularization parameter alpha starting with a not so high value, say 10."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R-squared score (training): 0.968\n",
      "R-squared score (validation): 0.931\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train the polynomial regression for degree 3 coupled with Lasso and call it `polyreg3_lasso`. Try a few differnt values for the regularization parameter alpha."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R-squared score (training): 0.000\n",
      "R-squared score (validation): -0.000\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using the following function for the root mean-squared error (RMSE), compare the different regression models, preferably by plotting a graph. Similarly, plot a graph to compare the $R^2$ scores as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_rmse(reg):\n",
    "    y_pred_train = reg.predict(X_train_poly)\n",
    "    train_rmse = np.sqrt(mean_squared_error(y_train_poly, y_pred_train))\n",
    "    y_pred_valid = reg.predict(X_valid_poly)\n",
    "    valid_rmse = np.sqrt(mean_squared_error(y_valid_poly, y_pred_valid))\n",
    "    return train_rmse, valid_rmse"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next steps:\n",
    "* Read the test.csv file into a dataframe\n",
    "* Feature engineer the dataframe in exactly the same way as above by using function `feature_engineering`.\n",
    "* Scale the quantitative variables the same way as above\n",
    "* Train a model\n",
    "* Predict\n",
    "* Convert the predictions using exponential (since our model is built using log for the target variable)\n",
    "* Create a dataframe for the results with the right format\n",
    "* Save it into csv file and submit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Acknowledgement:\n",
    "\n",
    "The credits for the images used in the above are as follows.\n",
    "- Image 1: https://commons.wikimedia.org/wiki/File:Gaussian_kernel_regression.png\n",
    "\n",
    "For the feature engineering of the data, inspiration is taken from the following two publically shared sources:\n",
    "* Udacity Github Repository: https://github.com/udacity/deep-learning-v2-pytorch/tree/master/project-bikesharing\n",
    "* Kaggle kernel by Vivek Srinivasan: https://www.kaggle.com/viveksrinivasan/eda-ensemble-model-top-10-percentile\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
